{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Goal: ML model that takes video features (title and description) and classifies it as **educational** or **non-educational** video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Collecting training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup DB, Youtube Data API and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = os.getenv('MONGO_URI')\n",
    "mongo_client = MongoClient(uri)\n",
    "db = mongo_client['youtube-db']\n",
    "\n",
    "train_col = db['training_col']\n",
    "test_col = db['test_col']\n",
    "\n",
    "# Setting up the api client\n",
    "key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "client = build('youtube', 'v3', developerKey=key)\n",
    "\n",
    "# Categories to 0 (non educational) or 1 (educational)\n",
    "def to_binary_category(c_id):\n",
    "    if c_id in [27, 28, 25, 35]: # educational ids\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Cleaning text from punctuation\n",
    "def remove_punctuation(text):\n",
    "    return \"\".join([c.lower() for c in text if c not in string.punctuation])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Collecting data using popular educational videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdb8824-6e92-46a8-93f3-6ceeec5087d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\"TED-Ed - Lessons Worth Sharing\", \"SmarterEveryDay - To teach you something new every day!\", \"Vsauce\", \"AsapSCIENCE\", \n",
    "           \"National Geographic | Science, Exploration And Adventure\", \"CrashCourse | Educational Videos\", \"Numberphile\", \"Computerphile\",\n",
    "          \"In a nutshell - Kurzegesagt\", \"Ted Talks\", \"Veritasium\", \"Vox - Explain the news\", \"Khan academy english\", \"The Backyard Scientist\",\n",
    "          \"Big think - Get smarter, faster, for success in the knowledge economy\", \"MIT OpenCourseWare\", \"Science Channel | Science Videos\",\n",
    "          \"minuteearth\", \"3Blue1Brown\", \"Washington Post\", \"The Organic Chemistry Tutor\", \"tecmath | Math Videos\", \"BBC Earth Lab\", \"Stanford University\",\n",
    "          \"Astrum | YouTube\", \"Philosophy Tube | Philosophical YouTube Channel\", \"BrainCraft\", \"OUlearn\", \"BSI Academy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631ee84c-c4a3-469d-8e8a-2d8f416a0093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch and insert data for multiple queries (educational)\n",
    "\n",
    "for q in queries:\n",
    "    print(q)\n",
    "    # hit a search query\n",
    "    search = client.search().list(q=q, part='snippet', type='video', maxResults=50).execute()\n",
    "    \n",
    "    # filtering out the videoIds from the search query\n",
    "    videoIds = [v['id']['videoId'] for v in search['items']]\n",
    "    \n",
    "    # fetching video content data for all videoIds\n",
    "    data = client.videos().list(id=videoIds, part=\"snippet\").execute()\n",
    "    cleaned_data = [{\"video_id\": e['id'], 'title': remove_punctuation(e['snippet']['title']), 'description': remove_punctuation(e['snippet']['description']), 'category_id':  \n",
    "                     to_binary_category(int(e['snippet']['categoryId']))} for e in data['items']]\n",
    "    \n",
    "    train_col.insert_many(cleaned_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Collecting data using dataset from Kaggle (better option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b089b0-c396-4dff-abc0-343937ccc18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/US_youtube_trending_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae9dc48-c04f-460c-94ff-cd1d8601b598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'video_id': '3C66w5Z0ixs',\n",
       " 'title': 'i asked her to be my girlfriend',\n",
       " 'description': 'subscribe to brawadis ▶ httpbitlysubscribetobrawadis\\r\\rfollow me on social\\r▶ twitter httpstwittercombrawadis\\r▶ instagram httpswwwinstagramcombrawadis\\r▶ snapchat brawadis\\r\\rhi i’m brandon awadis and i like to make dope vlogs pranks reactions challenges and basketball videos don’t forget to subscribe and come be a part of the brawadsquad',\n",
       " 'category_id': 0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = []\n",
    "for index, row in df.iterrows():\n",
    "    if pd.isna(row[\"description\"]): \n",
    "        row[\"description\"] = \"\"\n",
    "    data.append({\n",
    "        \"video_id\": row[\"video_id\"],\n",
    "        \"title\": remove_punctuation(row[\"title\"]),\n",
    "        \"description\": remove_punctuation(row[\"description\"]),\n",
    "        \"category_id\": to_binary_category(row[\"categoryId\"])\n",
    "    })\n",
    "\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31436224-0034-4a3b-9804-ba0016234683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x7fce2c7e4980>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_col.insert_many(data[45000:55000]) # index 0 to 20.000 and 25.000 and 55.000 is train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Building and testing ML models using Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22b83eb-35f9-4291-ac55-5fc622aa5ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building ML Pipeline\n",
    "\n",
    "sgd_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1, 2))),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=1000, tol=None)),\n",
    "    ])\n",
    "\n",
    "sgd_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97be547-0362-4950-a806-0a9610f269a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics on test data from split:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95      7970\n",
      "           1       0.15      0.99      0.27       140\n",
      "\n",
      "    accuracy                           0.91      8110\n",
      "   macro avg       0.58      0.95      0.61      8110\n",
      "weighted avg       0.99      0.91      0.94      8110\n",
      "\n",
      "Metrics on new random data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96      4948\n",
      "           1       0.13      1.00      0.23        52\n",
      "\n",
      "    accuracy                           0.93      5000\n",
      "   macro avg       0.57      0.97      0.60      5000\n",
      "weighted avg       0.99      0.93      0.96      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluating metrics on test data\n",
    "\n",
    "predicted = sgd_clf.predict(X_test)\n",
    "print(\"Metrics on test data from split:\")\n",
    "print(metrics.classification_report(predicted, y_test))\n",
    "\n",
    "# Evaluating clf against completly new random data\n",
    "\n",
    "predicted_new = sgd_clf.predict(X_new)\n",
    "print(\"Metrics on new random data:\")\n",
    "print(metrics.classification_report(predicted_new, y_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367c5068-d639-428d-bb70-d6f707346813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building ML Pipeline\n",
    "\n",
    "rf_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1, 2))),\n",
    "    ('clf', RandomForestClassifier()),\n",
    "    ])\n",
    "\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d9c79e-cac8-499d-9888-ad14a9430a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7185\n",
      "           1       0.98      1.00      0.99       925\n",
      "\n",
      "    accuracy                           1.00      8110\n",
      "   macro avg       0.99      1.00      0.99      8110\n",
      "weighted avg       1.00      1.00      1.00      8110\n",
      "\n",
      "Metrics on new random data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98      4743\n",
      "           1       0.63      0.98      0.77       257\n",
      "\n",
      "    accuracy                           0.97      5000\n",
      "   macro avg       0.81      0.97      0.88      5000\n",
      "weighted avg       0.98      0.97      0.97      5000\n",
      "\n",
      "[[4596  147]\n",
      " [   6  251]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluating metrics on test data\n",
    "\n",
    "predicted = rf_clf.predict(X_test)\n",
    "print(metrics.classification_report(predicted, y_test))\n",
    "\n",
    "# Evaluating clf against completly new random data\n",
    "\n",
    "predicted_new = rf_clf.predict(X_new)\n",
    "print(\"Metrics on new random data:\")\n",
    "print(metrics.classification_report(predicted_new, y_new))\n",
    "print(metrics.confusion_matrix(predicted_new, y_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8778125a-7fa2-4b9f-8651-4d7ea8175ac7",
   "metadata": {},
   "source": [
    "### c) Multi Layer Perceptron Classifier (best option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367c5068-d639-428d-bb70-d6f707346813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building ML Pipeline\n",
    "\n",
    "mlp_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1, 2))),\n",
    "    ('cclf', MLPClassifier(verbose=True))\n",
    "    ])\n",
    "    \n",
    "mlp_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25777aab-6184-4da0-9dfb-f7796171b4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7176\n",
      "           1       0.99      1.00      0.99       934\n",
      "\n",
      "    accuracy                           1.00      8110\n",
      "   macro avg       0.99      1.00      1.00      8110\n",
      "weighted avg       1.00      1.00      1.00      8110\n",
      "\n",
      "Metrics on new random data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99      9366\n",
      "           1       0.71      0.97      0.82       634\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.85      0.97      0.90     10000\n",
      "weighted avg       0.98      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluating metrics on test data\n",
    "predicted = mlp_clf.predict(X_test)\n",
    "print(metrics.classification_report(predicted, y_test))\n",
    "\n",
    "# Evaluating clf against completly new random data\n",
    "predicted_new = mlp_clf.predict(X_new)\n",
    "print(\"Metrics on new random data:\")\n",
    "print(metrics.classification_report(predicted_new, y_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps and challenges\n",
    "\n",
    "### - optimize the features being analyzed\n",
    "\n",
    "### - optimize the MLP parameters\n",
    "\n",
    "### - integrate the created model in a web service using Flask\n",
    "\n",
    "### - add feedback functionality"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
